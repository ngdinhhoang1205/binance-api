services:
  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    environment:
      - IN_DOCKER=true

  worker:
    build: .
    command: python main.py
    depends_on:
      - redis
  airflow-init:
    image: apache/airflow:2.9.2
    depends_on:
      - timescaledb
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__FERNET_KEY: 'ZYLXfJ8Td-W9XBhjIOHwlS8sJBtj-P5Lf0W5vZM-tdg='
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://joeynguyen:joeynguyen@timescaledb:5432/binance-api
      AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.default'
      AIRFLOW__WEBSERVER__SECRET_KEY: '2MYdegfDZJzh2sc_acoGrm1H_b531mOEK2x43ksEiTk'
      PYTHONPATH: /opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./binanceapi_etl:/opt/airflow/binanceapi_etl
      - /var/run/docker.sock:/var/run/docker.sock
    entrypoint: bash -c "airflow db migrate && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"
  airflow-webserver:
    image: apache/airflow:2.9.2
    container_name: airflow-webserver
    depends_on:
      - redis
      - timescaledb
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__FERNET_KEY: 'ZYLXfJ8Td-W9XBhjIOHwlS8sJBtj-P5Lf0W5vZM-tdg='
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://joeynguyen:joeynguyen@timescaledb:5432/binance-api
      AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.default'
      AIRFLOW__WEBSERVER__SECRET_KEY: '2MYdegfDZJzh2sc_acoGrm1H_b531mOEK2x43ksEiTk'
      PYTHONPATH: /opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./binanceapi_etl:/opt/airflow/binanceapi_etl
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8080:8080"
    command: webserver

  airflow-scheduler:
    image: apache/airflow:2.9.2
    container_name: airflow-scheduler
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__FERNET_KEY: 'ZYLXfJ8Td-W9XBhjIOHwlS8sJBtj-P5Lf0W5vZM-tdg='
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://joeynguyen:joeynguyen@timescaledb:5432/binance-api
      AIRFLOW__API__AUTH_BACKEND: 'airflow.api.auth.backend.default'
      AIRFLOW__WEBSERVER__SECRET_KEY: '2MYdegfDZJzh2sc_acoGrm1H_b531mOEK2x43ksEiTk'
      PYTHONPATH: /opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./binanceapi_etl:/opt/airflow/binanceapi_etl
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler

  flask-app:
    build:
      context: .
    command: python app.py
    container_name: binance-api
    ports:
      - "5000:5000"
    depends_on:
      - worker
    environment:
      - REDIS_HOST=redis

  timescaledb:
    image: timescale/timescaledb:latest-pg14
    container_name: timescaledb
    environment:
      POSTGRES_USER: joeynguyen
      POSTGRES_PASSWORD: joeynguyen
      POSTGRES_DB: binance-api
    ports:
      - "5432:5432"
    volumes:
      - timescale-data:/var/lib/postgresql/data
  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.9.0
    volumes:
      - ./dbt_binance:/usr/app
      - ./dbt_binance/.dbt:/root/.dbt
    working_dir: /usr/app
    depends_on:
      - timescaledb
    entrypoint: ["dbt"]  # Use dbt as entrypoint
    command: ["debug"]  # Or any dbt subcommand
volumes:
  timescale-data:
